version: "3.8"

services:
  voice-llm-stack:
    build:
      context: .
      dockerfile: base/Dockerfile
    image: ${DOCKERHUB_USERNAME:-schnicklbob}/quickpod-voice-llm:latest
    container_name: voice-llm-stack
    gpus: all
    ports:
      - "22:22"
      - "8000:8000"   # SillyTavern UI
      - "11434:11434" # Ollama API
      - "7851:7851"   # AllTalk API
      - "7852:7852"   # AllTalk Gradio UI [web:109]
      - "7052:7052"   # AllTalk Finetune UI [web:121]
      - "8686:8686"   # QuickPod Health Port [web:198]
      - "9000:9000"   # SD 1.5 Image API [web:108]
    environment:
      - ST_PORT=8000
      - OLLAMA_PORT=11434
      - ALLTALK_PORT=7851
      - HEALTH_PORT=8686
      - HF_TOKEN=${HF_TOKEN:-}
      - DEVICE=cuda
    volumes:
      # Match the case-sensitive paths from your base/Dockerfile
      - ./sillytavern:/workspace/SillyTavern:rw
      - ./ollama:/root/.ollama:rw
      - ./alltalk:/workspace/alltalk_v2:rw
      - ./image_store:/app/generated_images:rw
      - ./logs:/var/log/quickpod:rw
    # Critical for Dolphin 20B + SD 1.5 concurrency
    shm_size: "16gb"
    restart: unless-stopped


