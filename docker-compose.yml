services:
  voice-llm-stack:
    build:
      context: .
      dockerfile: base/Dockerfile
    image: ${DOCKERHUB_USERNAME:-schnicklbob}/quickpod-voice-llm:latest
    container_name: voice-llm-stack
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "22:22"
      - "8000:8000"
      - "11434:11434"
      - "7851:7851"
      - "8686:8686"
    environment:
      - ST_PORT=8000
      - OLLAMA_PORT=11434
      - ALLTALK_PORT=7851
      - HEALTH_PORT=8686
    volumes:
      # Persist installations across restarts
      - ./sillytavern:/home/node/app:rw
      - ./ollama:/root/.ollama:rw
      - ./alltalk:/workspace/alltalk_tts:rw
      - ./venv:/opt/venv:rw
      - ./logs:/var/log/quickpod:rw
    shm_size: "8gb"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8686 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 6
      start_period: 120s  # Longer for first-run installs
